# Dockerfile for Triton Inference Server with quantization tools
# Build complete image with all dependencies pre-installed
FROM nvcr.io/nvidia/tritonserver:24.09-py3

# Set working directory
WORKDIR /workspace

# Install system dependencies (OpenGL libraries for OpenCV)
RUN apt-get update && apt-get install -y \
    python3-pip \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip first
RUN pip3 install --no-cache-dir --upgrade pip

# Install PyTorch first with specific version and ROCm 6.4
RUN pip3 install --no-cache-dir \
    torch==2.8.0 \
    torchvision==0.23.0 \
    torchaudio==2.8.0 \
    --index-url https://download.pytorch.org/whl/rocm6.4

# Install other Python dependencies for quantization
RUN pip3 install --no-cache-dir \
    ultralytics==8.3.226 \
    onnx==1.19.1 \
    onnxsim==0.4.36 \
    python-dotenv \
    numpy \
    pillow \
    opencv-python-headless

# Set Python path
ENV PYTHONPATH=/workspace:$PYTHONPATH

# Default command (can be overridden)
CMD ["/bin/bash"]

